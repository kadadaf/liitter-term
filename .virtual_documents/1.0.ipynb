#导入模型及相关的包
import torch 
from torch import nn
import sklearn
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
from transformers import BertTokenizer, ErnieModel
# import transformers
# print(transformers.__version__)
tokenizer = BertTokenizer.from_pretrained("nghuyong/ernie-3.0-xbase-zh")
model = ErnieModel.from_pretrained("nghuyong/ernie-3.0-xbase-zh")


#定义超参数
batch_size = 32
num_epochs = 10
learning_rate = 2e-5
num_classes = 16


# 定义分类器，可以根据需要修改
class Classifier(nn.Module):  # 定义一个继承自nn.Module的类，用于构建分类器
    def __init__(self, model, num_classes):  # 定义初始化方法，接收两个参数：model和num_classes
        super().__init__()  # 调用父类的初始化方法
        self.model = model  # 将model赋值给self.model，model是一个预训练的模型，如BERT
        self.dropout = nn.Dropout(0.1)  # 定义一个dropout层，用于防止过拟合，设置丢弃率为0.1
        self.linear = nn.Linear(model.config.hidden_size, num_classes)
        # 定义一个线性层，用于将模型的输出映射到分类数，输入维度为模型的隐藏层大小，输出维度为分类数

    def forward(self, input_ids, attention_mask):
        # 定义前向传播方法，接收两个参数：input_ids和attention_mask
        outputs = self.model(input_ids, attention_mask)
        # 调用模型的前向传播方法，得到模型的输出，是一个元组，包含最后一层的输出和池化后的输出
        pooled_output = outputs[1]  
        # 取出元组中的第二个元素，即池化后的输出，是一个张量，形状为[batch_size, hidden_size]
        pooled_output = self.dropout(pooled_output)
        # 将池化后的输出通过dropout层，得到一个新的张量
        logits = self.linear(pooled_output)
        # 将dropout后的输出通过线性层，得到一个新的张量，形状为[batch_size, num_classes]，表示每个样本在每个类别上的得分
        return logits  # 返回logits张量


# 实例化分类器
classifier = Classifier(model, num_classes)  # 用model和num_classes作为参数，创建一个Classifier对象，赋值给classifier变量



